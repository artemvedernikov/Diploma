\documentclass[12pt]{article} % тип документа
\usepackage[T2A]{fontenc} % Поддержка русских букв
\usepackage[utf8]{inputenc} % кодировка 
\usepackage[english,russian]{babel} % языковой пакет
\usepackage{amsmath,amsfonts} % шрифты
\usepackage[colorlinks,urlcolor=blue]{hyperref} % для гиперссылок
\usepackage{anysize} % для отступов	
\usepackage{setspace} % интервал
\usepackage{dsfont} % индикатор
\onehalfspacing % уточняет интервал
\usepackage{indentfirst} % чтобы первый абзац в разделе тоже был с отступом
\marginsize{2.5cm}{2cm}{1cm}{1cm} % поля

\title{Построение рекомендательной системы, основанной на итерационном улучшении качества классификации}
\author{Ведерников А.В.}

\begin{document}
\maketitle


\section{Введение}
\par Рекомендательные системы представляют из себя программы, которые помогают пользователям в выборе подходящих им объектов из некоторой библиотеки.  %TODO: найти статью где будет введено это понятие и сосласться на нее, можно использовать [1] из iterative smooting technology %
Это могут быть фильмы(Netflix), товары(Amazon), музыкальные исполнители(Last.fm). В процессе вычисления рекомендаций эти системы используют оценки, сделанные пользователями, а также информацию о пользователях и рекомендуемых объектах.


\par
Существует несколько базовых подходов к построение рекомендательных систем: алгоритмы, основанные на анализе содержания(content-based), алгоритмы, анализирующие схожесть предпочтений пользователей --- коллаборативная фильтрация(Collaborative filtering) и гибридные алгоритмы. Последние подразделяются на монолитные, последовательные и параллельные.
\par
Системы, основанные на анализе содержания, при прогнозировании оценок сопоставляют информацию о рекомендуемых объектах(жанр, автор, год выпуска и т.д.) с информацией об уже оцененных пользователем объектах. Система предлагает объекты, схожие с объектами, понравившимися пользователю. Для поиска часто используются ключевые слова, хеш-теги. 
\par
Основная идея алгоритма коллаборативной фильтрации заключается в предложении новых объектов для конкретного пользователя на основе оценок, проставленных "похожими" пользователями. Мера близости пользователей зависит от конкретной реализации.
\par
Алгоритмы коллаборативной фильтрации могут основываться либо на анализе имеющих оценок(memory-based), либо на построении и анализе некоторой модели данных(model based). Часто при построении методов коллаборативной фильтрации является объединение двух описанных подходов.
\par
Первая группа алгоритмов на начальном этапе работы оценивает степень схожести между пользователями. Далее происходит отбор наиболее значимых пользователей -- ближайших соседей, недостающие рейтинги оцениваются в соответствии с их предпочтениями.
\par
Методы второй группы на первом этапе строят статистическую модель оценок пользователей, которая обучается на тренировочном раборе данных, после чего используется для оценки. Здесь широко используются различные алгоритмы кластеризации, байесовские сети, а также методы уменьшения размерности данных и разложения матриц(SVD). Алгоритмы, основанные на построении  модели, показывают высокие результаты при работе с сильно разреженными данными, недостатки модели связаны с необходимостью соблюдения компромисса между точностью оценок и размером модели.

\par 
Одним из главных недостатков как алгоритмов, основанных на анализе содержания, так и коллаборативной фильтрации является проблема выдачи релевантных рекомендаций для новых пользователей и для новых объектов и называется проблемой холодного старта. Существует множество способов ее решения, большинство из которых сводится к добавлению в систему дополнительной информации о пользователях и объектов.

В данной работе построен \textit{новый рекомендательный алгоритм}, основанный на коллаборативной фильтрации, проведено его тестирование и сравнение с другими широко используемыми рекомендательными алгоритма и дана оценка полученных результатов.


\section{Обзор литературы}
\par 
Необходимо обратить внимание, что большая часть методов, используемых при построении рекомендательных систем носит эмпирический характер и имеет большое число дополнительных параметров, значения которых подбираются отдельно для каждого конкретного набора данных на основе проведенных испытаний.
\subsection{Методы, использующие кластеризацию пользователей}
\par
В работе "A new collaborative recommendation approach based on users clustering using artificial bee colony algorithm"$\cite{bees}$ был представлен алгоритм коллаборативной фильтрации, в основе которого лежит кластеризации пользователей исходя из проставленных ими рейтингов методом k-средних с использованием алгоритма искуственной пчелиной колонии(Artificial bee colony algorithm) для определения начальных центров кластеров. В качестве меры близости пользователей внутри кластера была использована модифицированная косинусная метрика, в которую добавлен вес рекомендуемого объекта. На прогнозируемую оценку для пользователя $u \in U$  влияли только оценки пользователей одного с ним класса. 
%Добавить результаты, словами описать циферками. Какой то переход сделать к описанию следующей статьи.
\par 
Кольчугин и Макарь в статье "Метод коллаборативной фильтрации для масштабируемых рекомендательных систем"$\cite{hash}$ при построении алгоритма коллаборативной фильтрации для кластеризации пользователей используют разработанный ими алгоритм LSH-CLC, основанный на методе локально-чувствительного хеширования LSH. Этот метод используется для нахождения ближайших соседей. На основе найденных схожих пользователей впоследствии формируются кластеры. Прогнозируемые оценки для пользователя $u \in U$ рассчитываются исходя из его сходства с центроидами кластеров. В качестве меры близости между пользователями используется корреляция Пирсона.  В тестах данный метод показал качество, близкое к SVD-алгоритму. Благодаря использованию хеширования удалось достичь высокой скорости работы алгоритма.   

\subsection{Итерационные методы}
\par
Zhang, Cuff, Kulkarni в работе "Iterative collaborative filtering for recommender systems with sparse data"$\cite{itercf}$ описывают алгоритм коллаборативной фильтрации, основной задачей которого является повышение качества рекомендаций при работе с данными высокой разреженности. Для этого авторы при оценке неизвестного рейтинга объекта $i \in I$ для пользователя $u \in U$ предлагают воспользоваться итерационным алгоритмом, на каждом шаге которого происходит оценка рейтингов на основе попарных расстояний между пользователями, оценки полученные на i-м шаге используются для подсчета расстояний на i+1-м. Алгоритм завершается, когда разница между значениями оценок на соседних шагах станет меньше заданного значения $\epsilon=0.01$. Тестовые результаты показали, что алгоритм сходится очень быстро и успешно завершается после 2-4 итераций. Помимо высокого качества работы при высокой разреженности матрицы рейтингов (1\%) , алгоритм продемонстрировал хорошие результаты и при умеренной разреженности(5\%), уступив только модифицированному SVD-алгоритму.

\par
Статья "iterative smoothing technique for improving stability of recommender system"$\cite{smoothing}$ посвящена алгоритму и итерационного сглаживания для увеличения стабильности рекомендательных систем. Этот метод используется совместно с любым другим рекомендательным алгоритмом, при его использовании повышается не только стабильность, но и качество рекомендаций. На первом шаге неизвестные рейтинги оцениваются с использованием базового алгоритма Т, далее в течение K итераций полученные на предыдущем шаге оценки добавлялись ко входным данным, после чего происходила переоценка рейтингов с использованием расширенных входных данных. Оптимальное значение K вычислялось отдельно для каждого набора тестовых данных методов на основе полученных результатов. Авторы применяли описанный метод в паре с различными рекомендательными алгоритмами, среди которых присутстствовали SVD и основанная как на пользователях, так и на объектах коллаборативная фильтрация. При использовании итеративного сглаживания у всех базовых алгоритмов было отмечено улучшение показателей стабильности(около 50\% у методов коллаборативной фильтрации, 14\% у SVD) и качества рекомендаций(1,4\%). 

\subsection{Заключение к обзору литературы}
В данной работе рассмотрен алгоритм, сочетающий в себе обе предыдущие категории подходов: пересчет рейтингов происходит в зависимости проведенной кластеризации объектов.


\section{Методология и формулировка задачи}
\subsection{Формулировка задачи}
Имеется конечный набор объектов $I=\{i_{1}, i_{2}, \dots, i_{m}\}$ и конечный набор пользователей $U=\{u_{1}, u_{2}, \dots, u_{n}\}$
Положим $r_{ui}$ - рейтинг, который пользователь $u\in U$ поставил объекту $i\in I$. Тогда n x m матрицу  $R = (r_ui) $ будем называть мартицей рейтинговю. Задачей рекомендательной системы является оценка неизвестных рейтингов $r_{ui}$. Главной особенностью рекомендательных систем является высокая разреженность мартицы R.
Далее пользователю рекомендуются рейтинги с самой высокой оценкой. 

\subsection{Метрики сходства}
Важным шагов при построении рекомендательной системы является задание функции похожести между пользователями и/или объектами. Ниже приведены наиболее часто встречающиеся ффункции похожести пользователей, функции похожести объектов вводятся аналогично.
\begin{itemize}

\item{Корреляция Пирсона}
%TODO: тут вставить почему она крутая(как просил Рыжов))
\[
s_{uv} = \frac{\sum_{i \in I_{uv}} (r_{ui} - \bar{r}_{ui})}{\sqrt{\sum_{i \in I_{uv}}  (r_{ui} - \bar{r}_{u})^2} \sqrt{\sum_{i \in I_{uv}}  (r_{vi} - \bar{r}_{v})^2}}
\]
\item{Косинусная метрика}

\[
s_{uv} = \frac{\sum_{i \in I_{uv}} r_{ui}r_{vi}} {\sqrt{\sum_{i \in I_{uv}} r_{ui}^2} \sqrt{\sum_{i \in I_{uv}} r_{vi}^2}}
\]

\vspace*{2\baselineskip}
\item{Другие метрики}
\[s_{uv} = \frac{|\{i \in I: r_{ui} = r_{vi}\}|}{\sqrt{\sum_{i \in I_{uv}} (r_{ui} - r_{vi})^2 }}
\]
\end{itemize}
\subsection{Нечеткая кластеризация}
Имеется $X=\{x_{1},\dots,x_{n}\}$ - множество объектов, $C=\{c_{1},\dots,c_{m}\}$ - множество кластеров, задана функция расстояния между объектами $d(x, y): X\times X  \to \mathbb{R}$ В классической задачи кластеризации требуется разбить X на непересекающиеся подмножества, называемые кластерами, так, чтобы каждый кластер состоял из объектов, близких по метрике $dist$, а объекты разных классов существенно отличались. При этом каждому объекту $x_{i} \in X$ приписывается кластер $c_{i} \in C$
\par
 Особенностью нечеткой кластеризации является то, что объекту $x \in X$ приписывается не номер кластера, а вещественный вектор, элементами которого являются степени принадлежности x кластерам из C. $\lambda(x)=(\lambda_{1}(x),\dots,\lambda_{m}(x)) $, при этом выполняются следующие условия:
 \begin{itemize}
 \item $\forall x \in X: \forall c: 1\leq c \leq m:  \lambda_{m}(x) \in [0,1]$
 \item $\forall x \in X: \sum_{j=1,\dots,c} \lambda_{j}(x) = 1$
 \item $\forall i : 0 < \sum_{j=1}^{n} \lambda_{i}(x_{j}) < |X|  $
 \end{itemize} 
 \par
 %Использовался алгоритм нечеткой классификации FANNY (Kaufman, Rousseeuw)$\cite{fanny}$. Этот алгоритм основывается на минимизации функции 
%\[
%	V=\sum_{v=1..k} \frac{\sum_{i,j} \lambda_{v}^r(i) \lambda_{v}^r(j) dist(i,j)}{2 \sum_{j} \lambda_{v}^r(j)}
%\]
%где $\lambda_{v}(j) = $ k - число кластеров(задается как параметр алгоритма), r - мера нечеткости, $r \in (1, \infty)$, $\lambda_{i}(x)$ - степень принадлежности элемента $x \in X$ кластеру $c_{i} \in C$.


\section{Метод Итерационного улучения качества классификации}
\subsection{Описание алгоритма}
Качество существующих рекомендательных систем, используюущих кластеризацию пользователей, можетсильно страдать из-за высокой разреженности выходных данных. Некоторые алгоритмы борются с этой проблемой путем заполнения пропущенных значений стандартными, например, нулями или средним значением рейтинга, проставленным пользователем или среднего значения, проставленного объекту. Ниже приведен алгоритм, решающий проблему разреженности.
\par

Для каждого пользователя $u \in U$ , для которого требуется рассчитать рекомендации

\begin{enumerate} 


\item Выбирается метрика, используемая для рассчета расстояния между пользователями. Далее вычисляется матрица расстояний между пользователями. Положим $t = t_{0}$


\item Кластеризация пользователей
С помощью алгоритма нечетких к-средних множество пользователей разбивается на t кластеров $\{k_{1},\dots,k_{t}\}=K$
Каждому пользователю $u \in U$ приписывается вектор $\lambda(u)=(\lambda_{1}(u),\dots,\lambda_{t}(u)), \lambda(u)\in\mathbb{N}, t=|K|$

Введем понятие качества кластеризации пользователя $u \in U$ :
$\varphi_{p}(u) = \min_{j} \{k_{i_{j}} \in K: \sum_{j} \lambda_{i_{j}}(u) >= p\}, 0 < p < 1$ 
\par
Положим $\Lambda(u) = k \in K: \lambda_{k}(u) = \max_{j} \{\lambda_{j}(u)\}$ 
\par
Положим $\lambda_{p}(u) = \{k \in K: \lambda_{k_{1}} \geq\lambda_{k_{2}} \geq\dots, \sum_{j}\lambda_{k_{j}} \geq p\}$

\item Полученное качество кластеризации $\varphi_{p}(u)$ сравнивается с заранее заданным порогом $\hat{K}$. Если $\varphi_{p}(u) \leq \cap{K}$ , то неизвестные $r_{ui}$ подсчитываются по формуле 
\[
	r_{ui} = \bar{r}_{u} + \frac{\sum_{v \in \hat{U}_{u}} s_{uv}(r_{vi} - \bar{r}_v)}{\sum_{v \in \hat{U}_{u}} |s_{uv}|}
\] ,где $\bar{U}_{u} = \{u \in U:\Lambda(u) \in  \lambda_{p}(u)\}$, $\bar{r}_{v}$ - средний рейтинг, проставленный пользователем $v \in U$, в противном случае по этой формуле пересчитываются все неизвестные рейтинги для $u \in \bar{U}_{u}$, и процесс возвращается к стадии 2 с той разницей, что в качестве входных данных используются только $u \in \bar{U}_{u}$ и искомый пользователь.
$t = t + \delta t$, 

\end{enumerate}

\subsection{Дополнительные параметры}

\begin{itemize}

\item Начальное количество кластеров K
в какойто-статье сказано, что ок брать $K <= \frac{\sqrt{n}}{2} $
\item Пороговое качество кластеризации p
\item Сдвиг числа кластеров $\delta m$
\item Пороговое число совместно отрейтингованых объектов M

\end{itemize}

\section{Тестирование}
\subsection{Способы оценки рекомендательных систем}
\begin{itemize}
\item  Качество 
\par Стандартными оценками качества работы рекомендательного алгоритма являются среднеквадратичное отклоенение (Root mean squared error, RMSE) и среднее абсолютное отклоение (Mean absolute error, MAE)
\[
	RMSE=\sqrt{\frac{1}{|T|}\sum_{(u,i)\in T} (\hat{r}_{ui} - r_{ui})^2}
\]
\[	
	MAE=\sqrt{\frac{1}{|T|}\sum_{(u,i)\in T} |\hat{r}_{ui} - r_{ui}|}
\]
\item Стабильность
\par Стабильность рекомендательной системы показывает, насколько оценки, полученные системой для конкретных объектв, изменяются при появлении новых пользовательских оценок, полностью или частично совпадающих с предыдущими оценками, данными системой. Таким образом, метод оценки стабильности системы состоит из двух шагов: на первом %TODO:найти ссылку на статью где вводился метод - взять [2] bpb из статьи про стабильность %
шаге система рассчитывает оценки неизвестных рейтингов на некоторых входных данных. Затем случайное подмножество полученных рекомендаций добавляется к начальным входным данным. На втором шаге алгоритм рассчитывает оценки на расширенных входных данных, после чего сравниваются оценки, полученные алгоритом для оставшихся рейтингов на обоих шагах. Мера называется Среднеквадратичный сдвиг (Root mean squared shift, RMSS)
\[
	RMSS=\sqrt{\sum_{(u,i) \in P_{1} \cap P_{2})} (P_{1}(u,i) - P_{2}(u,i))^2 /  |P_{1} \cap P_{2}|}
\]  
где $P_{1}$ и $P_{2}$ - рекомендации, полученные на шагах 1 и 2 соответственно.
\end{itemize}
\subsection{Проверочные данные}
Для проверки качества работы алгорита были использованы данные сайта http://movielens.com. В выборке содержались данные о 100000 оценкок, проставленных  943 пользователями 
1664 фильмам. Каждый пользователь оценил как минимум 20 фильмов. Этот набор данных вместе с набором данных, предоставленным компанией Netflix является стандартным для оценки качества работы рекомендательных систем и используется в большинстве работ на эту тему.
В исходном наборе разреженность матрицы рейтингов составляла 6,3\% , при тестировании она искуственно понимажалась до 1\%


\subsection{Процесс тестирования}
В процессе тестирования алгоритм сравнивался со следующими:
\begin{itemize}
\item SVD
\item Рекомендация наиболее популярных объектов
\item Коллаборативная фильтрация, основанная на пользователях
\item Коллаборативная фильтрация, основанная на объектах
содержимое...
\end{itemize}


\subsection{Результаты}

\section{Заключение}

\begin{thebibliography}{99}
\bibitem{bees} пчелиная колония
\bibitem{hash} хеширование
\bibitem{smoothing} итеративное сглаживание
\bibitem{itercf} итеративное CF
\bibitem{hybrid} кластеризация для гибридных РС
\bibitem{fanny} fanny fuzzy clustering algorhitm

\end{thebibliography}



\end{document}

