\documentclass[12pt]{article} % тип документа
\usepackage[T2A]{fontenc} % Поддержка русских букв
\usepackage[utf8]{inputenc} % кодировка 
\usepackage[english,russian]{babel} % языковой пакет
\usepackage{amsmath,amsfonts} % шрифты
\usepackage[colorlinks,urlcolor=blue]{hyperref} % для гиперссылок
\usepackage{anysize} % для отступов	
\usepackage{setspace} % интервал
\usepackage{dsfont} % индикатор
\onehalfspacing % уточняет интервал
\usepackage{indentfirst} % чтобы первый абзац в разделе тоже был с отступом
\marginsize{2.5cm}{2cm}{1cm}{1cm} % поля
\usepackage{amsthm} % работа с теоремами
\newtheorem{statement}{Утверждение}

\title{Построение рекомендательной системы, основанной на итерационном улучшении качества классификации}
\author{Ведерников А.В.}

\begin{document}
\maketitle


\section{Введение}
\par Рекомендательные системы представляют из себя программы, которые помогают пользователям в выборе подходящих им объектов из некоторой библиотеки.  %TODO: найти статью где будет введено это понятие и сосласться на нее, можно использовать [1] из iterative smooting technology %
Это могут быть фильмы(Netflix), товары(Amazon), музыкальные исполнители(Last.fm). В процессе вычисления рекомендаций эти системы используют оценки, сделанные пользователями, а также информацию о пользователях и рекомендуемых объектах.


\par
Существует несколько базовых подходов к построение рекомендательных систем: алгоритмы, основанные на анализе содержания(Content-based), алгоритмы, анализирующие схожесть предпочтений пользователей --- коллаборативная фильтрация(Collaborative filtering) и гибридные алгоритмы. 
\par
Системы, основанные на \textit{анализе содержания}, при прогнозировании оценок сопоставляют информацию о рекомендуемых объектах(жанр, автор, год выпуска и т.д.) с информацией об уже оцененных пользователем объектах. Пользователю предлагаются объекты, схожие с теми, которые он оотметил как понравившиеся. Для поиска часто используются ключевые слова, хеш-теги. 
\par
Основная идея алгоритма \textit{коллаборативной фильтрации }заключается в предложении новых объектов для конкретного пользователя на основе оценок, проставленных "похожими" пользователями. Мера близости пользователей зависит от конкретной реализации.
\par
Алгоритмы коллаборативной фильтрации могут основываться либо на анализе имеющих оценок(memory-based), либо на построении и анализе некоторой модели данных(model based). Часто при построении рекомендательных систем эти подходы объединяются. Рассмотрим виды коллаборативной фильтрации подробнее.
\par
Первая группа алгоритмов на начальном этапе работы оценивает степень схожести между пользователями. Далее происходит отбор наиболее значимых пользователей -- ближайших соседей, недостающие рейтинги оцениваются в соответствии с их предпочтениями.
\par
Методы второй группы на первом этапе строят статистическую модель оценок пользователей, которая обучается на тренировочном раборе данных, после чего используется для оценки. Здесь широко используются различные алгоритмы кластеризации, байесовские сети, а также методы уменьшения размерности данных и разложения матриц (SVD). Алгоритмы, основанные на построении  модели, показывают высокие результаты при работе с сильно разреженными данными. Недостатки модели связаны с необходимостью соблюдения компромисса между точностью оценок и размером модели.

\par
Гибридные рекомендательные системы сочетают в себе несколько различных подходов к оценке неизвестных рейтингов и подразделяются на параллельные, последовательные и монолитные. В параллельных системах оценки вычисляются как линейные комбинации результатов, полученных при независимой работе нескольких рекомендательных алгоритмов. В последовательных системах результат работы одного алгоритма используется в качестве входных данных для другого. Монолитные рекомендательные  системы используют несколько подходов в рамках единого алгоритма, не позволяя изолированно рассматривать результаты работы конкретного метода.

\par 
Одним из главных недостатков как алгоритмов, основанных на анализе содержания, так и коллаборативной фильтрации является проблема выдачи релевантных рекомендаций для новых пользователей и для новых объектов. В литературе данный недостаток называют "проблемой холодного старта"\cite{coldstart}. Существует множество способов ее решения, большинство из которых сводится к добавлению в систему дополнительной информации о пользователях и объектах.

\par
Второй проблемой большинства существующих рекомендательных алгоритмов является низкое качество рекомендаций при работе с данными высокой разреженности. Наиболее часто используемыми методами устронения этого недостатка является добавление к данным некоторого количества стандартных рейтингов\cite{empiricalanalysis}. Тестирование показывает, что подобный подход заметну улучшает качество рекомендаций, однако его результаты сильно зависят от выбора дополнительных параметров алгоритма.  

\par
В данной работе построен \textit{новый рекомендательный алгоритм}, основной задачей которого является повышение качества рекомендаций при высокой разреженности выходных данных. Метод основан на применении коллаборативной фильтрации. На каждой итерации множества схожих пользователей определяются с использованием нечеткой кластеризации, далее происходит оценка неизвестных рейтингов. Проведено тестирование и сравнение метода с другими широко используемыми рекомендательными алгоритма, дана оценка полученных результатов.


\section{Обзор литературы}
\par 
Необходимо обратить внимание, что большая часть методов, используемых при построении рекомендательных систем носит \textit{эмпирический }характер и имеет большое число дополнительных параметров, значения которых подбираются отдельно для каждого конкретного набора данных на основе проведенных испытаний. На примере следующих статей, приведены возможные подходы к построению рекомендаций.
\subsection{Методы, использующие кластеризацию пользователей}
\par
В работе "A new collaborative recommendation approach based on users clustering using artificial bee colony algorithm"$\cite{bees}$ был представлен алгоритм коллаборативной фильтрации, в основе которого лежит кластеризации пользователей исходя из проставленных ими рейтингов методом k-средних с использованием алгоритма искуственной пчелиной колонии(Artificial bee colony algorithm) для определения начальных центров кластеров. В качестве меры близости пользователей внутри кластера была использована модифицированная косинусная метрика, в которую добавлен вес рекомендуемого объекта. На прогнозируемую оценку для пользователя $u \in U$  влияли только оценки пользователей одного с ним класса. Тестирование метода проводилось на наборе данных MovieLens, состоящем из 100000 оценок 943 пользователей, проставленных 1682 фильмам. Разреженность данных составляла 6,3\%. Алгоритм сравнивался с другими методами на основе коллаборативной фильтрации и показал самый высокий показатель качества рекомендаций.

\par 
Кольчугин и Макарь в статье "Метод коллаборативной фильтрации для масштабируемых рекомендательных систем"$\cite{hash}$ при построении алгоритма коллаборативной фильтрации для кластеризации пользователей используют разработанный ими алгоритм LSH-CLC, основанный на методе локально-чувствительного хеширования LSH. Этот метод используется для нахождения ближайших соседей. На основе найденных схожих пользователей впоследствии формируются кластеры. Прогнозируемые оценки для пользователя $u \in U$ рассчитываются исходя из его сходства с центроидами кластеров. В качестве меры близости между пользователями используется корреляция Пирсона. Благодаря использованию хеширования удалось достичь линейной зависимости сложности кластеризации пользователей от их общего числа \textit{n}, таким образом сложность рекомендательного алгоритма также зависит от \textit{n} линейно. Тестирование производилось на наборе данных MovieLens, содержащем 100000 оценок и имеющих разреженность 6,3\%. В тестах данный метод показал качество, близкое к SVD-алгоритму. При оценке времени работы использовались наборы данных, содержащие от 1000 до 6000 пользователей. При использовании информации о 1000 пользователях время работы алгоритма составило 5 секунд, при 4500 порядка 30 секунд, при 6000 --- около 60 секунд. Полученные результаты подтверждают линейную зависимость времени работы алгоритма от количества пользователей.  

\subsection{Итерационные методы}
\par
Zhang, Cuff, Kulkarni в работе "Iterative collaborative filtering for recommender systems with sparse data"$\cite{itercf}$ описывают алгоритм коллаборативной фильтрации, основной задачей которого является повышение качества рекомендаций при работе с данными высокой разреженности. Для этого авторы при оценке неизвестного рейтинга объекта $i \in I$ для пользователя $u \in U$ предлагают воспользоваться итерационным алгоритмом, на каждом шаге которого происходит оценка рейтингов на основе попарных расстояний между пользователями, оценки полученные на i-м шаге используются для подсчета расстояний на i+1-м. Алгоритм завершается, когда разница между значениями оценок на соседних шагах станет меньше заданного значения $\varepsilon$. При тестировании алгоритма было использовано значение $\varepsilon=0,01$. Оно было получено на основе результатов предварительной настройки и проверки алгоритма. Тестирование производилось на наборе данных MovieLens, состоящем из 100000 рейтингов, проставленных 943 пользователями 1682 фильмам. Оригинальный набор данных был дополнительно обработан с целью понизить показатель разреженности до 5\% и 1\%. (Начальное значение 6.3\%). Результаты показали, что алгоритм сходится очень быстро и успешно завершается после 2-4 итераций. Помимо высокого качества работы при высокой разреженности матрицы рейтингов (1\%) , алгоритм продемонстрировал хорошие результаты и при умеренной разреженности(6,3\%), уступив только модифицированному с использованием коллаборативной фильтрации SVD-алгоритму\cite{cfbasedsvd}.

\par
Статья "Iterative smoothing technique for improving stability of recommender system"$\cite{smoothing}$ посвящена алгоритму итерационного сглаживания для увеличения стабильности рекомендательных систем. Этот метод используется совместно с любым другим рекомендательным алгоритмом. Использование такого подхода позволяет повысить качество и стабильность рекомендаций \footnote{Показатели качества и стабильности будут рассмотрены подробнее в разделе Тестирование}. Метод состоит в следующем: на первом шаге неизвестные рейтинги оцениваются с использованием базового алгоритма Т, далее в течение K итераций полученные на предыдущем шаге оценки добавлялись ко входным данным, после чего происходила переоценка рейтингов с использованием расширенных входных данных. Оптимальное значение K вычисляется отдельно для каждого набора тестовых данных методов на основе полученных результатов. На стадии тестирования авторы сравнивали результаты работы различных рекомендательных алгоритмов в паре с описанным методом и без него. Среди рассмотренных методов присутстствовали SVD и основанная как на пользователях, так и на объектах коллаборативная фильтрация. В качестве тестовых данных, как и в рассмотренных выше работах, использовались данные MovieLens, содержащие 100000 и 400627 рейтингов с разреженностью 6,3\% и 4,45\% соответственно, а также данные сайта Netflix, содержащие 105256 рейтингов, разреженность составила 1,17\%. При использовании итеративного сглаживания на всех наборах данных у всех базовых алгоритмов было отмечено улучшение показателей стабильности(приблизительно на 50\% у методов коллаборативной фильтрации, на 14\% у SVD) и качества рекомендаций(в среднем на 1,4\%). 

\subsection{Заключение к обзору литературы}
Были рассмотрены работы, посвященные двум широко используемым подходам к построение рекомендательных систем: кластеризация пользователей и итерационный процесс подсчета оценок неизвестных рейтингов. В данной работе рассмотрен алгоритм, сочетающий в себе обе описанные методики: на каждой итерации оценка рейтингов происходит в зависимости проведенной кластеризации объектов.


\section{Методология и формулировка задачи}
\subsection{Формулировка задачи}
Имеется конечный набор объектов $I=\{i_{1}, i_{2}, \dots, i_{m}\}$ и конечный набор пользователей $U=\{u_{1}, u_{2}, \dots, u_{n}\}$
Положим $r_{ui}$ --- рейтинг, который пользователь $u\in U$ поставил объекту $i\in I$. Тогда n x m матрицу  $R = (r_ui) $ будем называть мартицей рейтингов. Задачей рекомендательной системы является оценка неизвестных рейтингов $r_{ui}$. Далее пользователю рекомендуются объекты, чьи неизвестные рейтинги по результатам работы алгоритма получили самую высокую оценку.


\subsection{Метрики сходства}
Важным шагом при построении рекомендательной системы является задание функции похожести между пользователями и/или объектами. Ниже приведены наиболее часто встречающиеся функции похожести пользователей, аналогично вводятся функции похожестb для объектов.
\begin{itemize}

\item{Корреляция Пирсона}
%TODO: тут вставить почему она крутая(как просил Рыжов))
\[
s_{uv} = \frac{\sum_{i \in I_{uv}} (r_{ui} - \bar{r}_{ui})(r_{vi} - \bar{r}_{vi})}{\sqrt{\sum_{i \in I_{uv}}  (r_{ui} - \bar{r}_{u})^2} \sqrt{\sum_{i \in I_{uv}}  (r_{vi} - \bar{r}_{v})^2}},\qquad s_{uv} \in [-1, 1] 
\]

Большее значение коэффициента корреляции Пирсона соответствует парам объектов с большей похожестью. Проблемы могут возникать при оценке пользователей, поставивших всем объектам одинаковый рейтинг. В таком случае предлагается вычислить ковариацию двух пользователей\\ $cov(u, v) = \sum_{i \in I_{uv}} (r_{ui} - \bar{r}_{ui})(r_{vi} - \bar{r}_{vi})$ и положить $s_{uv}=sign(cos(u,v)) * 0,5$



\item{Косинусное расстояние}

\[
s_{uv} = \frac{\sum_{i \in I_{uv}} r_{ui}r_{vi}} {\sqrt{\sum_{i \in I_{uv}} r_{ui}^2} \sqrt{\sum_{i \in I_{uv}} r_{vi}^2}},\qquad s_{uv} \in [-1, 1] 
\]

Большее значение косинусного расстояния соответствует парам объектов с большей похожестью.

\end{itemize}
\subsection{Кластеризация методом k-средних(k-means)}



\subsection{Нечеткая кластеризация методом с-средних(fuzzy c-means)}
Имеется $X=\{x_{1},\dots,x_{n}\}$ --- множество объектов, $C=\{c_{1},\dots,c_{m}\}$ - множество кластеров, задана функция расстояния между объектами $d(x, y): X\times X  \to \mathbb{R}$ В классической задачи кластеризации требуется разбить X на непересекающиеся подмножества, называемые кластерами, так, чтобы каждый кластер состоял из объектов, близких по метрике $dist$, а объекты разных классов существенно отличались. При этом каждому объекту $x_{i} \in X$ приписывается кластер $c_{i} \in C$
\par
 Особенностью нечеткой кластеризации является то, что объекту $x \in X$ приписывается не номер кластера, а вещественный вектор, элементами которого являются степени принадлежности x кластерам из C. $\lambda(x)=(\lambda_{1}(x),\dots,\lambda_{m}(x)) $, при этом выполняются следующие условия:
 \begin{itemize}
 \item $\forall x \in X: \forall c: 1\leq c \leq m:  \lambda_{m}(x) \in [0,1]$
 \item $\forall x \in X: \sum_{j=1,\dots,c} \lambda_{j}(x) = 1$
 \item $\forall i : 0 < \sum_{j=1}^{n} \lambda_{i}(x_{j}) < |X|  $
 \end{itemize} 
 \par
 %Использовался алгоритм нечеткой классификации FANNY (Kaufman, Rousseeuw)$\cite{fanny}$. Этот алгоритм основывается на минимизации функции 
%\[
%	V=\sum_{v=1..k} \frac{\sum_{i,j} \lambda_{v}^r(i) \lambda_{v}^r(j) dist(i,j)}{2 \sum_{j} \lambda_{v}^r(j)}
%\]
%где $\lambda_{v}(j) = $ k - число кластеров(задается как параметр алгоритма), r - мера нечеткости, $r \in (1, \infty)$, $\lambda_{i}(x)$ - степень принадлежности элемента $x \in X$ кластеру $c_{i} \in C$.

Алгоритм нечеткой кластеризации методом с-средних стремится минимизировать функцию

\[
	J_{m} = \sum_{i=1}^{N} \sum_{j=1}^{C} u_{ij}^m dist(x_{i}, c_{j})^2, 1 \leq m < \infty
\]

где $u_{ij}$ --- степень принадлежности элемента $x_{i}$ кластеру $C_{j}$

	

\subsection{Методы предварительной обработка данных}
\textit{Нормализация}

\par

\textit{Бинаризация} используется 



\section{Метод Итерационного улучения качества классификации}
\subsection{Описание алгоритма}
Качество существующих рекомендательных систем, использующих коллаборативную фильтрацию, может сильно страдать из-за высокой разреженности выходных данных. При отсутствии достаточного количества входной информации возникают трудности при подсчете меры близости между пользователями. Существует несколько способов борьбы с проблемой разреженности. Некоторые алгоритмы заполняют часть пропущенных значений стандартными, например, нулями или средним значением рейтинга, проставленным конкретным пользователем, или среднего значения, соответствующего конкретному объекту. Существуют также итерационные алгоритмы, оценивающие неизвестные рейтинги, используя при подсчете расстояний между пользователями оценки, полученные на предыдущей итерации. 
\par
Ниже приведен алгоритм, в основе которого лежит идея коллаборативной фильтрации. 

Для каждого пользователя $u \in U$ , для которого требуется рассчитать рекомендации

\begin{enumerate} 


\item Выбирается метрика, используемая для рассчета расстояния между пользователями. Далее вычисляется матрица расстояний между пользователями. Положим $t = t_{0}$.


\item Кластеризация пользователей
С помощью алгоритма нечетких к-средних множество пользователей разбивается на t кластеров $\{k_{1},\dots,k_{t}\}=K$
Каждому пользователю $u \in U$ приписывается вектор $\lambda(u)=(\lambda_{1}(u),\dots,\lambda_{t}(u)), \lambda(u)\in\mathbb{N}, t=|K|$

Введем понятие качества кластеризации пользователя $u \in U$ :
$\varphi_{p}(u) = \min_{j} \{k_{i_{j}} \in K: \sum_{j} \lambda_{i_{j}}(u) >= p\}, 0 < p < 1$ 
\par
Положим $\Lambda(u) = k \in K: \lambda_{k}(u) = \max_{j} \{\lambda_{j}(u)\}$ 
\par
Положим $\lambda_{p}(u) = \{k \in K: \lambda_{k_{1}} \geq\lambda_{k_{2}} \geq\dots, \sum_{j}\lambda_{k_{j}} \geq p\}$

\item Полученное качество кластеризации $\varphi_{p}(u)$ сравнивается с заранее заданным порогом $\hat{K}$. Если $\varphi_{p}(u) \leq \hat{K}$ , то неизвестные $r_{ui}$ подсчитываются по формуле 
\[
	r_{ui} = \bar{r}_{u} + \frac{\sum_{v \in \hat{U}_{u}} s_{uv}(r_{vi} - \bar{r}_v)}{\sum_{v \in \hat{U}_{u}} |s_{uv}|}
\] 
где $\bar{U}_{u} = \{u \in U:\Lambda(u) \in  \lambda_{p}(u)\}$, $\bar{r}_{v}$ --- средний рейтинг, проставленный пользователем $v \in U$, в противном случае по этой формуле пересчитываются все неизвестные рейтинги для $u \in \bar{U}_{u}$, и процесс возвращается к стадии 2 с той разницей, что в качестве входных данных используются только $u \in \bar{U}_{u}$ и искомый пользователь.
$t = t + \delta t$, 

\end{enumerate}

\subsection{Сходимость}

\begin{statement}
Если $k_{i} $ невозрастает с ростом i то алгоритм завершается при   0 < p $\leq \frac {K - 1}{K}$ где K ---начальное число кластеров пользователей
\end{statement}
\begin{proof}

Пусть на i-м шаге мы получили $t_{i}$ кластеров. 
Худший случай - полная нечеткость: $\forall i: \lambda_{i}(u) = \frac{1}{t_{i}}$
Тогда чтобы точно откинуть часть пользователей нам нужно, чтобы $\frac{k_{i} - 1}{k_{i}} \geq p$ (1)
\par
так как функция $\frac{x-1}{x}$ возрастает на $(0, \infty)$ , а $k_{i} $ невозрастает с ростом i  то  условие (1) будет выполнено $\forall i = 1,\dots$ при 0 < p $\leq \frac {K - 1}{K}$
\end{proof}

\subsection{Дополнительные параметры}

\begin{itemize}

\item Начальное количество кластеров K
в какойто-статье сказано, что ок брать $K <= \frac{\sqrt{n}}{2} $
\item Пороговое качество кластеризации p
\item Сдвиг числа кластеров $\delta m$
\item Пороговое число совместно отрейтингованых объектов M

\end{itemize}

\section{Тестирование}


\subsection{Оценка рекомендательных систем}

Существует три основных методики проверки работы рекомендательных систем: проверка с использованием тестовых данных и пользовательская проверка. При использовании первого метода имеющиеся данные об оставленных пользователями рейтингах разделяются на две группы: обучающая и проверочная. Рекомендательному алгоритму подаются на вход данные из обучающей выборки, результаты его работы сравниваются с проверочными данными. При пользовательской проверке работа системы оценивается в реальном времени либо с использованием тестировщиков, пользующихся системой и анализирующих полученные рекомендации, либо анализом поведения рядовых пользователей в зависимости от предложенных рекомендаций.

Имеется большое число критериев, по которым может быть оценена рекомендательная система. Предложенные рекомендации могут оцениваться по таким критериям как качество, стабильность, разнообразие. Кроме того рекомендательная система, как и любой алгоритм фильтрации информации, может быть оценена по таким параметрам, как устойчивость к атакам, масштабируемость, адаптируемость и скорость работы.

Стандартными оценками \textit{качества }работы рекомендательного алгоритма являются среднеквадратичное отклонение (Root mean squared error, RMSE) и среднее абсолютное отклоение (Mean absolute error, MAE)
\[
	RMSE=\sqrt{\frac{1}{|T|}\sum_{(u,i)\in T} (\hat{r}_{ui} - r_{ui})^2}
\]
\[	
	MAE=\sqrt{\frac{1}{|T|}\sum_{(u,i)\in T} |\hat{r}_{ui} - r_{ui}|}
\]
где \textit{Т} --- тестовая выборка,  $\hat{r}_{ui}$ --- полученная оценка рейтинга объекта $i \in I$, поставленного пользователем $u \in U$,  $r_{ui}$ --- истинное значение рейтинга. Низкие показатели RMSE и MAE соответствуют алгоритмам с высоким качеством .
  
\par
\textit{Стабильность} рекомендательной системы показывает, насколько оценки, полученные системой для конкретных объектв, изменяются при появлении новых пользовательских оценок, полностью или частично совпадающих с предыдущими оценками, данными системой. Метод оценки стабильности системы приведен ниже:
\begin{enumerate}

\item Cистема  на основе входных данных \textit{D} рассчитывает оценки неизвестных рейтингов $P_{1}$ . 
\item Cлучайное подмножество $P \subset P_{1}$ полученных оценок добавляется к начальным входным данным. 
\item Алгоритм рассчитывает оценки $P_{2}$  на расширенных входных данных $D \cup P$ 
\item Cравниваются оценки, полученные алгоритом для оставшихся рейтингов на обоих шагах. 
\end{enumerate}
Мера называется \textit{Среднеквадратичный сдви}г (Root mean squared shift, RMSS)
\[
	RMSS=\sqrt{\sum_{(u,i) \in P_{1} \cap P_{2})} (P_{1}(u,i) - P_{2}(u,i))^2 /  |P_{1} \cap P_{2}|}
\]  

\subsection{Проверочные данные}
Для проверки качества работы алгорита были использованы данные сайта\\ http://movielens.com. Выборка состоит из 100000 оценкок, проставленных  943 пользователями 1664 фильмам. Каждый пользователь оценил как минимум 20 фильмов. Этот набор данных является стандартным средством, используемым при тестировании и оценке качества работы рекомендательных систем и используется в большинстве работ на эту тему. Помимо оценок с MovieLens  в работах, исследующих рекомендательные алгоритмы, часто используются данные компании Netflix.
В исходных данных MovieLense разреженность матрицы рейтингов составляла 6,3\% , при тестировании она искуственно понижалась до 1\%.

\subsection{Процесс тестирования}
В процессе тестирования алгоритм сравнивался со следующими:
\begin{itemize}
\item SVD
\item Рекомендация наиболее популярных объектов
\item Коллаборативная фильтрация, основанная на пользователях
\item Коллаборативная фильтрация, основанная на объектах
\end{itemize}


\subsection{Результаты}

\section{Заключение}

\newpage
\begin{thebibliography}{99}
\bibitem{bees} пчелиная колония
\bibitem{hash} хеширование
\bibitem{smoothing} итеративное сглаживание
\bibitem{itercf} итеративное CF
\bibitem{hybrid} кластеризация для гибридных РС
\bibitem{fanny} fanny fuzzy clustering algorhitm
\bibitem{coldstart} Methods and metrics for cold-start recommendations
\bibitem{cfbasedsvd} [11] из itercf
\bibitem{empiricalanalysis} imperical analysis of predictive algorithms for cf - [8] из itercf
\bibitem{fuzzycmeans} Pattern Recognition with Fuzzy Objective Function Algoritms

\end{thebibliography}



\end{document}

